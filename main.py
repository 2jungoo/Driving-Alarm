"""
ì°¨ëŸ‰ ê±°ë¦¬ ì¸¡ì • ë° ê²½ê³  ì‹œìŠ¤í…œ
Vehicle Distance Detection and Warning System

ë³¸ ì‹œìŠ¤í…œì€ YOLO ê°ì²´ ê²€ì¶œê³¼ ì»´í“¨í„° ë¹„ì „ ê¸°ìˆ ì„ í™œìš©í•˜ì—¬
ì „ë°© ì°¨ëŸ‰ì˜ ê±°ë¦¬ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¸¡ì •í•˜ê³  ì•ˆì „ ê²½ê³ ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import cv2
import numpy as np
from ultralytics import YOLO
import os
import pyttsx3
import threading
import queue
import time
import platform

# ==================== ì‹œìŠ¤í…œ ì„¤ì • ====================
VIDEO_PATH = "./videos/nD_1.mp4"  # ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
IMAGE_WIDTH = 640  # ì²˜ë¦¬í•  ì´ë¯¸ì§€ ë„ˆë¹„
IMAGE_HEIGHT = 480  # ì²˜ë¦¬í•  ì´ë¯¸ì§€ ë†’ì´
DETECTION_CONFIDENCE = 0.5  # YOLO ê²€ì¶œ ì‹ ë¢°ë„ ì„ê³„ê°’
YOLO_MODEL = 'yolov8s.pt'  # ì‚¬ìš©í•  YOLO ëª¨ë¸

# ==================== ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ íŒŒë¼ë¯¸í„° ====================
CAMERA_HEIGHT = 2.0  # ì¹´ë©”ë¼ ì„¤ì¹˜ ë†’ì´ (ë¯¸í„°)
CAMERA_TILT_ANGLE = 15  # ì¹´ë©”ë¼ í•˜í–¥ ê°ë„ (ë„)
CAMERA_FOV = 75  # ì¹´ë©”ë¼ ì‹œì•¼ê° (ë„)
ORIGINAL_WIDTH = 1920  # ì›ë³¸ í•´ìƒë„ ë„ˆë¹„
ORIGINAL_HEIGHT = 1080  # ì›ë³¸ í•´ìƒë„ ë†’ì´

# ==================== ì•ˆì „ ê±°ë¦¬ ì„ê³„ê°’ ====================
WARNING_DISTANCE = 7.0  # ìœ„í—˜ ê±°ë¦¬ (ë¯¸í„°) - ë¹¨ê°„ìƒ‰ ê²½ê³ 
CAUTION_DISTANCE = 15.0  # ì£¼ì˜ ê±°ë¦¬ (ë¯¸í„°) - ì£¼í™©ìƒ‰ ê²½ê³ 

# ==================== ì°¨ì„  ê²€ì¶œ ì„¤ì • ====================
LANE_DETECTION = True  # ì°¨ì„  ê²€ì¶œ í™œì„±í™” ì—¬ë¶€
BOTTOM_CROP_RATIO = 0.3  # í•˜ë‹¨ ì˜ì—­ ì œê±° ë¹„ìœ¨ (ë³¸ë„¤íŠ¸ ì œê±°)

# ==================== ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì„¤ì • ====================
ENABLE_HISTOGRAM_EQUALIZATION = True  # íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” í™œì„±í™”
HISTOGRAM_METHOD = "CLAHE"  # í‰í™œí™” ë°©ë²• (CLAHE/GLOBAL)
CLAHE_CLIP_LIMIT = 2.0  # CLAHE í´ë¦½ í•œê³„ê°’
CLAHE_TILE_SIZE = 8  # CLAHE íƒ€ì¼ í¬ê¸°

# ==================== TTS ì„¤ì • ====================
TTS_RATE = 160  # ìŒì„± ì¶œë ¥ ì†ë„ (ë‹¨ì–´/ë¶„)
TTS_VOLUME = 0.9  # ìŒì„± ë³¼ë¥¨ (0.0~1.0)
WARNING_COOLDOWN = 4.0  # ìŒì„± ê²½ê³  ê°„ê²© (ì´ˆ)

# ì°¨ëŸ‰ í´ë˜ìŠ¤ ì •ì˜
VEHICLE_CLASSES = {
    2: 'car',  # ìŠ¹ìš©ì°¨
    3: 'motorcycle',  # ì˜¤í† ë°”ì´
    5: 'bus',  # ë²„ìŠ¤
    7: 'truck',  # íŠ¸ëŸ­
    1: 'bicycle'  # ìì „ê±°
}


class ImagePreprocessor:
    """
    ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í´ë˜ìŠ¤
    íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”ë¥¼ í†µí•œ ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ
    """

    def __init__(self):
        """ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”"""
        self.enable_histogram_eq = ENABLE_HISTOGRAM_EQUALIZATION
        self.method = HISTOGRAM_METHOD

        # CLAHE(Contrast Limited Adaptive Histogram Equalization) ê°ì²´ ìƒì„±
        if self.method == "CLAHE":
            self.clahe = cv2.createCLAHE(
                clipLimit=CLAHE_CLIP_LIMIT,
                tileGridSize=(CLAHE_TILE_SIZE, CLAHE_TILE_SIZE)
            )
            print(f"âœ… CLAHE ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            print(f"âœ… Global Histogram Equalization í™œì„±í™”")

    def apply_histogram_equalization(self, image):
        """
        íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” ì ìš©
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (BGR)
        Returns:
            enhanced_image: í–¥ìƒëœ ì´ë¯¸ì§€
        """
        if not self.enable_histogram_eq:
            return image

        try:
            # BGRì„ YUV ìƒ‰ê³µê°„ìœ¼ë¡œ ë³€í™˜ (Yì±„ë„ì—ë§Œ í‰í™œí™” ì ìš©)
            yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)

            if self.method == "CLAHE":
                # ì ì‘í˜• íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” ì ìš©
                yuv[:, :, 0] = self.clahe.apply(yuv[:, :, 0])
            else:
                # ì „ì—­ íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” ì ìš©
                yuv[:, :, 0] = cv2.equalizeHist(yuv[:, :, 0])

            # YUVë¥¼ BGRë¡œ ì¬ë³€í™˜
            enhanced_image = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)
            return enhanced_image

        except Exception as e:
            print(f"âŒ íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” ì˜¤ë¥˜: {e}")
            return image

    def preprocess_frame(self, frame):
        """
        ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        Args:
            frame: ì…ë ¥ í”„ë ˆì„
        Returns:
            processed_frame: ì „ì²˜ë¦¬ëœ í”„ë ˆì„
        """
        processed_frame = self.apply_histogram_equalization(frame)
        return processed_frame


class SafeSpeaker:
    """
    ì•ˆì „í•œ TTS(Text-to-Speech) ì‹œìŠ¤í…œ
    ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ìŒì„± ì¶œë ¥ì„ ì²˜ë¦¬í•˜ì—¬ ë©”ì¸ í”„ë¡œê·¸ë¨ ë¸”ë¡œí‚¹ ë°©ì§€
    """

    def __init__(self):
        """TTS ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.queue = queue.Queue()  # ìŒì„± ë©”ì‹œì§€ í
        self.engine = None  # TTS ì—”ì§„
        self.thread = None  # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ
        self.running = True  # ì‹¤í–‰ ìƒíƒœ
        self.tts_available = False  # TTS ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
        self._init_engine()

    def _init_engine(self):
        """TTS ì—”ì§„ ì´ˆê¸°í™” ë° ì„¤ì •"""
        try:
            print("ğŸ”Š TTS ì—”ì§„ ì´ˆê¸°í™” ì‹œì‘...")

            # pyttsx3 TTS ì—”ì§„ ìƒì„±
            self.engine = pyttsx3.init()

            if self.engine is None:
                print("âŒ pyttsx3 ì—”ì§„ ìƒì„± ì‹¤íŒ¨")
                return

            # TTS ì†ì„± ì„¤ì •
            self.engine.setProperty('rate', TTS_RATE)
            self.engine.setProperty('volume', TTS_VOLUME)

            # í•œêµ­ì–´ ìŒì„± ì°¾ê¸° ë° ì„¤ì •
            voices = self.engine.getProperty('voices')
            if voices:
                for voice in voices:
                    if any(keyword in voice.name.lower() for keyword in
                           ['korean', 'ko', 'í•œêµ­', 'heami']):
                        self.engine.setProperty('voice', voice.id)
                        print(f"ğŸ‡°ğŸ‡· í•œêµ­ì–´ ìŒì„± ì„¤ì •: {voice.name}")
                        break

            # TTS ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
            test_message = "TTS í…ŒìŠ¤íŠ¸"
            self.engine.say(test_message)
            self.engine.runAndWait()

            self.tts_available = True

            # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘
            self.thread = threading.Thread(target=self._run)
            self.thread.daemon = True
            self.thread.start()
            print("âœ… TTS ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            print(f"âŒ TTS ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.tts_available = False

    def speak(self, message: str):
        """
        ìŒì„± ë©”ì‹œì§€ ì¶œë ¥ ìš”ì²­
        Args:
            message: ì¶œë ¥í•  í…ìŠ¤íŠ¸ ë©”ì‹œì§€
        """
        if not self.tts_available:
            print(f"âŒ TTS ë¹„í™œì„±í™”: {message}")
            return

        try:
            print(f"ğŸ”Š TTS íì— ì¶”ê°€: {message}")
            self.queue.put(message)
        except Exception as e:
            print(f"âŒ TTS í ì¶”ê°€ ì˜¤ë¥˜: {e}")

    def _run(self):
        """TTS ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹¤í–‰ í•¨ìˆ˜"""
        print("ğŸµ TTS ìŠ¤ë ˆë“œ ì‹œì‘")

        while self.running:
            try:
                # 1ì´ˆ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ë©”ì‹œì§€ ëŒ€ê¸°
                message = self.queue.get(timeout=1)

                if self.engine is not None:
                    print(f"ğŸµ TTS ì¬ìƒ: {message}")
                    self.engine.say(message)
                    self.engine.runAndWait()

            except queue.Empty:
                continue  # íƒ€ì„ì•„ì›ƒì€ ì •ìƒ ìƒí™©
            except Exception as e:
                print(f"âŒ TTS ì¬ìƒ ì˜¤ë¥˜: {e}")
                time.sleep(0.5)

    def stop(self):
        """TTS ì‹œìŠ¤í…œ ì¢…ë£Œ"""
        print("ğŸ”š TTS ì‹œìŠ¤í…œ ì¢…ë£Œ ì¤‘...")
        self.running = False

        if self.thread and self.thread.is_alive():
            self.thread.join(timeout=3)

        if self.engine:
            try:
                self.engine.stop()
            except:
                pass


class LaneDetector:
    """
    ì°¨ì„  ê²€ì¶œ í´ë˜ìŠ¤
    í—ˆí”„ ë³€í™˜ì„ ì´ìš©í•œ ì°¨ì„  ê²½ê³„ì„  ê²€ì¶œ
    """

    def __init__(self):
        """ì°¨ì„  ê²€ì¶œê¸° ì´ˆê¸°í™”"""
        self.lane_history = []  # ì°¨ì„  íˆìŠ¤í† ë¦¬ (ì•ˆì •í™”ìš©)

    def detect_my_lane_boundaries(self, image):
        """
        ìì°¨ ì°¨ì„ ì˜ ì–‘ìª½ ê²½ê³„ì„  ê²€ì¶œ
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€
        Returns:
            lane_image: ì°¨ì„ ì´ ê·¸ë ¤ì§„ ì´ë¯¸ì§€
            left_lane: ì™¼ìª½ ì°¨ì„  ì¢Œí‘œ
            right_lane: ì˜¤ë¥¸ìª½ ì°¨ì„  ì¢Œí‘œ
            masked_edges: ì—£ì§€ ê²€ì¶œ ê²°ê³¼
        """
        try:
            height, width = image.shape[:2]

            # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ ë° ë…¸ì´ì¦ˆ ì œê±°
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            blur = cv2.GaussianBlur(gray, (5, 5), 0)

            # 2. Canny ì—£ì§€ ê²€ì¶œ
            edges = cv2.Canny(blur, 130, 160)

            # 3. ê´€ì‹¬ ì˜ì—­(ROI) ì„¤ì • - ì‚¬ë‹¤ë¦¬ê¼´ í˜•íƒœ
            mask = np.zeros_like(edges)
            roi_vertices = np.array([[
                (width * 0.25, height * (1 - BOTTOM_CROP_RATIO)),  # ì™¼ìª½ í•˜ë‹¨
                (width * 0.40, height * 0.45),  # ì™¼ìª½ ìƒë‹¨
                (width * 0.60, height * 0.45),  # ì˜¤ë¥¸ìª½ ìƒë‹¨
                (width * 0.95, height * (1 - BOTTOM_CROP_RATIO))  # ì˜¤ë¥¸ìª½ í•˜ë‹¨
            ]], dtype=np.int32)

            cv2.fillPoly(mask, roi_vertices, 255)
            masked_edges = cv2.bitwise_and(edges, mask)

            # 4. í—ˆí”„ ë³€í™˜ì„ ì´ìš©í•œ ì§ì„  ê²€ì¶œ
            lines = cv2.HoughLinesP(
                masked_edges,
                rho=1,  # ê±°ë¦¬ í•´ìƒë„
                theta=np.pi / 180,  # ê°ë„ í•´ìƒë„
                threshold=40,  # ì„ê³„ê°’
                minLineLength=60,  # ìµœì†Œ ì„ ë¶„ ê¸¸ì´
                maxLineGap=20  # ìµœëŒ€ ì„ ë¶„ ê°„ê²©
            )

            # 5. ê²€ì¶œëœ ì§ì„ ì„ ì™¼ìª½/ì˜¤ë¥¸ìª½ ì°¨ì„ ìœ¼ë¡œ ë¶„ë¥˜
            left_lane, right_lane = self._classify_my_lane_boundaries(lines, width, height)

            # 6. ì°¨ì„ ì„ ì´ë¯¸ì§€ì— ê·¸ë¦¬ê¸°
            lane_image = self._draw_my_lane_boundaries(image, left_lane, right_lane)

            return lane_image, left_lane, right_lane, masked_edges

        except Exception as e:
            print(f"ì°¨ì„  ê²€ì¶œ ì˜¤ë¥˜: {e}")
            return image, None, None, None

    def _classify_my_lane_boundaries(self, lines, width, height):
        """
        ê²€ì¶œëœ ì§ì„ ë“¤ì„ ì™¼ìª½/ì˜¤ë¥¸ìª½ ì°¨ì„ ìœ¼ë¡œ ë¶„ë¥˜
        Args:
            lines: í—ˆí”„ ë³€í™˜ìœ¼ë¡œ ê²€ì¶œëœ ì§ì„ ë“¤
            width: ì´ë¯¸ì§€ ë„ˆë¹„
            height: ì´ë¯¸ì§€ ë†’ì´
        Returns:
            left_lane: ì™¼ìª½ ì°¨ì„  ì¢Œí‘œ
            right_lane: ì˜¤ë¥¸ìª½ ì°¨ì„  ì¢Œí‘œ
        """
        if lines is None:
            return None, None

        left_lines = []
        right_lines = []
        img_center = width // 2

        for line in lines:
            x1, y1, x2, y2 = line[0]

            # ê¸°ìš¸ê¸° ê³„ì‚° ë° í•„í„°ë§
            if x2 == x1:
                continue
            slope = (y2 - y1) / (x2 - x1)

            # ìˆ˜í‰ì„ ì´ë‚˜ ë„ˆë¬´ ê°€íŒŒë¥¸ ì„  ì œê±°
            if abs(slope) < 0.3 or abs(slope) > 2.0:
                continue

            line_center_x = (x1 + x2) // 2

            # ê¸°ìš¸ê¸°ì™€ ìœ„ì¹˜ë¡œ ì°¨ì„  ë¶„ë¥˜
            if slope < -0.3 and line_center_x < img_center + width * 0.1:
                left_lines.append([x1, y1, x2, y2, slope])
            elif slope > 0.3 and line_center_x > img_center - width * 0.1:
                right_lines.append([x1, y1, x2, y2, slope])

        # ê° ì°¨ì„ ì˜ ëŒ€í‘œì„  ê³„ì‚°
        left_lane = self._extrapolate_lane_boundary(left_lines, height)
        right_lane = self._extrapolate_lane_boundary(right_lines, height)

        return left_lane, right_lane

    def _extrapolate_lane_boundary(self, lines, height):
        """
        ì—¬ëŸ¬ ì„ ë¶„ì„ í•˜ë‚˜ì˜ ëŒ€í‘œ ì°¨ì„ ìœ¼ë¡œ í™•ì¥
        Args:
            lines: ì°¨ì„  í›„ë³´ ì„ ë¶„ë“¤
            height: ì´ë¯¸ì§€ ë†’ì´
        Returns:
            lane: í™•ì¥ëœ ì°¨ì„  ì¢Œí‘œ [x1, y1, x2, y2]
        """
        if not lines:
            return None

        # ëª¨ë“  ì„ ë¶„ì˜ ì ë“¤ì„ ìˆ˜ì§‘
        x_coords = []
        y_coords = []

        for line in lines:
            x1, y1, x2, y2 = line[:4]
            x_coords.extend([x1, x2])
            y_coords.extend([y1, y2])

        if len(x_coords) < 2:
            return None

        try:
            # 1ì°¨ ë‹¤í•­ì‹ í”¼íŒ…
            coeffs = np.polyfit(y_coords, x_coords, 1)
            slope = coeffs[0]
            intercept = coeffs[1]

            # ì´ë¯¸ì§€ ì „ì²´ ë†’ì´ë¡œ í™•ì¥
            y1 = int(height * (1 - BOTTOM_CROP_RATIO))  # í•˜ë‹¨
            y2 = int(height * 0.45)  # ìƒë‹¨

            x1 = int(slope * y1 + intercept)
            x2 = int(slope * y2 + intercept)

            # ìœ íš¨ì„± ê²€ì‚¬
            if 0 <= x1 <= height * 2 and 0 <= x2 <= height * 2:
                return [x1, y1, x2, y2]
            return None

        except Exception:
            return None

    def _draw_my_lane_boundaries(self, image, left_lane, right_lane):
        """
        ì°¨ì„  ê²½ê³„ì„ ì„ ì´ë¯¸ì§€ì— ê·¸ë¦¬ê¸°
        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€
            left_lane: ì™¼ìª½ ì°¨ì„  ì¢Œí‘œ
            right_lane: ì˜¤ë¥¸ìª½ ì°¨ì„  ì¢Œí‘œ
        Returns:
            lane_image: ì°¨ì„ ì´ ê·¸ë ¤ì§„ ì´ë¯¸ì§€
        """
        lane_image = image.copy()

        # ì™¼ìª½ ì°¨ì„  (ë¹¨ê°„ìƒ‰)
        if left_lane is not None:
            x1, y1, x2, y2 = left_lane
            cv2.line(lane_image, (x1, y1), (x2, y2), (0, 0, 255), 3)

        # ì˜¤ë¥¸ìª½ ì°¨ì„  (íŒŒë€ìƒ‰)
        if right_lane is not None:
            x1, y1, x2, y2 = right_lane
            cv2.line(lane_image, (x1, y1), (x2, y2), (255, 0, 0), 3)

        return lane_image

    def is_point_in_my_lane(self, point, left_lane, right_lane, image_width):
        """
        íŠ¹ì • ì ì´ ìì°¨ ì°¨ì„  ë‚´ë¶€ì— ìˆëŠ”ì§€ íŒë‹¨
        Args:
            point: í™•ì¸í•  ì ì˜ ì¢Œí‘œ (x, y)
            left_lane: ì™¼ìª½ ì°¨ì„  ì¢Œí‘œ
            right_lane: ì˜¤ë¥¸ìª½ ì°¨ì„  ì¢Œí‘œ
            image_width: ì´ë¯¸ì§€ ë„ˆë¹„
        Returns:
            bool: ì°¨ì„  ë‚´ë¶€ ì—¬ë¶€
        """
        px, py = point

        # ì°¨ì„  ê²€ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì˜ì—­ ì‚¬ìš©
        if left_lane is None and right_lane is None:
            return (image_width * 0.2 <= px <= image_width * 0.8) and \
                (py < image_width * (1 - BOTTOM_CROP_RATIO))

        def get_x_at_y(lane, y):
            """ì£¼ì–´ì§„ Yì¢Œí‘œì—ì„œ ì°¨ì„ ì˜ Xì¢Œí‘œ ê³„ì‚°"""
            if lane is None:
                return None
            x1, y1, x2, y2 = lane
            if y2 == y1:
                return x1
            t = (y - y1) / (y2 - y1)
            x = x1 + t * (x2 - x1)
            return x

        try:
            left_x = get_x_at_y(left_lane, py)
            right_x = get_x_at_y(right_lane, py)

            # ê° ê²½ìš°ì— ë”°ë¥¸ íŒë‹¨
            if left_x is not None and right_x is not None:
                return (left_x - 10 <= px <= right_x + 10) and \
                    (py < image_width * (1 - BOTTOM_CROP_RATIO))
            elif left_x is not None:
                return (px > left_x - 10) and \
                    (py < image_width * (1 - BOTTOM_CROP_RATIO))
            elif right_x is not None:
                return (px < right_x + 10) and \
                    (py < image_width * (1 - BOTTOM_CROP_RATIO))

            return False

        except Exception:
            return (image_width * 0.2 <= px <= image_width * 0.8) and \
                (py < image_width * (1 - BOTTOM_CROP_RATIO))


class VehicleDistanceDetector:
    """
    ì°¨ëŸ‰ ê±°ë¦¬ ì¸¡ì • ë©”ì¸ í´ë˜ìŠ¤
    YOLO ê°ì²´ ê²€ì¶œê³¼ ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ì´ìš©í•œ ê±°ë¦¬ ê³„ì‚°
    """

    def __init__(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            print("YOLO ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.model = YOLO(YOLO_MODEL)
            print(f"âœ… YOLO ëª¨ë¸ ({YOLO_MODEL}) ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

        # ê²€ì¶œ ì„¤ì •
        self.detection_confidence = DETECTION_CONFIDENCE

        # ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ íŒŒë¼ë¯¸í„°
        self.camera_height = CAMERA_HEIGHT
        self.camera_angle = CAMERA_TILT_ANGLE
        self.camera_fov = CAMERA_FOV
        self.original_width = ORIGINAL_WIDTH
        self.original_height = ORIGINAL_HEIGHT

        # ì•ˆì „ ê±°ë¦¬ ì„ê³„ê°’
        self.warning_distance = WARNING_DISTANCE
        self.caution_distance = CAUTION_DISTANCE

        # í•˜ìœ„ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.lane_detector = LaneDetector() if LANE_DETECTION else None
        self.speaker = SafeSpeaker()
        self.preprocessor = ImagePreprocessor()

        # ìŒì„± ê²½ê³  ì œì–´
        self.last_warning_time = 0

        # ê±°ë¦¬ ë§¤í•‘ í…Œì´ë¸” ìƒì„±
        self.distance_lookup_table = self._precompute_distance_lookup()

        print(f"ğŸ“· ì¹´ë©”ë¼ ì„¤ì •: ë†’ì´ {self.camera_height}m, ê°ë„ {self.camera_angle}Â°")
        print(f"âš ï¸ ê±°ë¦¬ ì„¤ì •: ê²½ê³  {self.warning_distance}m, ì£¼ì˜ {self.caution_distance}m")

    def _precompute_distance_lookup(self):
        """
        ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„°ë¥¼ ì´ìš©í•œ ê±°ë¦¬ ë§¤í•‘ í…Œì´ë¸” ìƒì„±
        ì‚¼ê°ë²•ì„ ì´ìš©í•˜ì—¬ Yì¢Œí‘œë³„ ì‹¤ì œ ê±°ë¦¬ë¥¼ ë¯¸ë¦¬ ê³„ì‚°
        """
        print("ğŸ“ ê±°ë¦¬ ë§¤í•‘ í…Œì´ë¸” ìƒì„± ì¤‘...")

        # Yì¢Œí‘œ ë¹„ìœ¨ ì„¤ì • (ìƒë‹¨ì—ì„œ í•˜ë‹¨ìœ¼ë¡œ)
        y_ratios = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 1.0]
        distances = []

        # ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° ê³„ì‚°
        camera_angle_rad = np.radians(self.camera_angle)
        aspect_ratio = self.original_width / self.original_height
        fov_diagonal_rad = np.radians(self.camera_fov)
        fov_v_rad = 2 * np.arctan(np.tan(fov_diagonal_rad / 2) / np.sqrt(1 + aspect_ratio ** 2))

        # ê° Yì¢Œí‘œ ë¹„ìœ¨ì— ëŒ€í•œ ê±°ë¦¬ ê³„ì‚°
        for y_ratio in y_ratios:
            if y_ratio < 1.0:
                # ì‚¼ê°ë²•ì„ ì´ìš©í•œ ê±°ë¦¬ ê³„ì‚°
                pixel_y = y_ratio * self.original_height
                center_y = self.original_height / 2
                pixel_offset = pixel_y - center_y

                # í”½ì…€ì„ ê°ë„ë¡œ ë³€í™˜
                pixel_to_angle_ratio = fov_v_rad / self.original_height
                offset_angle = pixel_offset * pixel_to_angle_ratio

                # ì§€ë©´ê¹Œì§€ì˜ ê°ë„
                ground_angle = camera_angle_rad + offset_angle

                # ê±°ë¦¬ ê³„ì‚°
                if ground_angle > 0.01:
                    distance = self.camera_height / np.tan(ground_angle)
                    distance = max(0.5, min(distance, 200.0))  # ë²”ìœ„ ì œí•œ
                else:
                    distance = 200.0
            else:
                # ìµœí•˜ë‹¨ì€ 1më¡œ ê³ ì •
                distance = 1.0

            distances.append(distance)

        return {
            'y_ratios': y_ratios,
            'distances': distances
        }

    def calculate_distance_by_interpolation(self, bbox, frame_height):
        """
        ë³´ê°„ë²•ì„ ì´ìš©í•œ ê±°ë¦¬ ê³„ì‚°
        Args:
            bbox: ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ [x1, y1, x2, y2]
            frame_height: í”„ë ˆì„ ë†’ì´
        Returns:
            distance: ê³„ì‚°ëœ ê±°ë¦¬ (ë¯¸í„°)
        """
        try:
            x1, y1, x2, y2 = bbox
            bottom_y = y2  # ê°ì²´ì˜ í•˜ë‹¨ Y ì¢Œí‘œ

            # í˜„ì¬ í•´ìƒë„ë¥¼ ì›ë³¸ í•´ìƒë„ë¡œ ìŠ¤ì¼€ì¼ë§
            height_scale = self.original_height / frame_height
            actual_bottom_y = bottom_y * height_scale

            # Yì¢Œí‘œë¥¼ ë¹„ìœ¨ë¡œ ë³€í™˜
            y_ratio = actual_bottom_y / self.original_height

            # ë£©ì—… í…Œì´ë¸”ì—ì„œ ì„ í˜• ë³´ê°„
            y_ratios = self.distance_lookup_table['y_ratios']
            distances = self.distance_lookup_table['distances']

            if y_ratio <= y_ratios[0]:
                distance = distances[0]
            elif y_ratio >= y_ratios[-1]:
                # ìµœí•˜ë‹¨ ì´ìƒì¸ ê²½ìš° ì™¸ì‚½
                extra_ratio = y_ratio - 1.0
                distance = 1.0 - (extra_ratio * 2.0)
                distance = max(0.5, distance)
            else:
                # ì„ í˜• ë³´ê°„
                distance = np.interp(y_ratio, y_ratios, distances)

            return distance

        except Exception as e:
            print(f"ê±°ë¦¬ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 10.0

    def speak_warning(self, object_name, distance):
        """
        ìŒì„± ê²½ê³  ì¶œë ¥ (ì¿¨ë‹¤ìš´ ì ìš©)
        Args:
            object_name: ê°ì²´ ì´ë¦„
            distance: ê±°ë¦¬
        """
        try:
            current_time = time.time()
            if current_time - self.last_warning_time > WARNING_COOLDOWN:
                warning_text = f"ì£¼ì˜! ì „ë°© {distance:.1f}ë¯¸í„°ì— {object_name}ê°€ ìˆìŠµë‹ˆë‹¤."
                print(f"ğŸš¨ [ìŒì„±ê²½ê³ ] {warning_text}")
                self.speaker.speak(warning_text)
                self.last_warning_time = current_time

        except Exception as e:
            print(f"âŒ ìŒì„± ê²½ê³  ì˜¤ë¥˜: {e}")

    def get_distance_color_and_status(self, distance):
        """
        ê±°ë¦¬ì— ë”°ë¥¸ ìƒ‰ìƒê³¼ ìƒíƒœ ë°˜í™˜
        Args:
            distance: ê±°ë¦¬ (ë¯¸í„°)
        Returns:
            color: BGR ìƒ‰ìƒ íŠœí”Œ
            status: ìƒíƒœ ë¬¸ìì—´
        """
        if distance <= self.warning_distance:
            return (0, 0, 255), "DANGER"  # ë¹¨ê°„ìƒ‰
        elif distance <= self.caution_distance:
            return (0, 165, 255), "CAUTION"  # ì£¼í™©ìƒ‰
        else:
            return (0, 255, 0), "SAFE"  # ì´ˆë¡ìƒ‰

    def detect_vehicles_with_distance(self, frame):
        """
        ì°¨ëŸ‰ ê²€ì¶œ ë° ê±°ë¦¬ ì¸¡ì • (ìì°¨ ì°¨ì„  í•„í„°ë§ í¬í•¨)
        Args:
            frame: ì…ë ¥ í”„ë ˆì„
        Returns:
            distance_frame: ê²°ê³¼ê°€ ê·¸ë ¤ì§„ í”„ë ˆì„
            vehicles_with_distance: ê²€ì¶œëœ ì°¨ëŸ‰ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # 1. ì°¨ì„  ê²½ê³„ì„  ê²€ì¶œ
            if self.lane_detector:
                lane_frame, left_lane, right_lane, edges = \
                    self.lane_detector.detect_my_lane_boundaries(frame)
            else:
                lane_frame, left_lane, right_lane, edges = frame, None, None, None

            # 2. YOLO ê°ì²´ ê²€ì¶œ
            results = self.model(
                frame,
                verbose=False,
                conf=self.detection_confidence,
                device='cpu'
            )

            distance_frame = lane_frame.copy()
            vehicles_with_distance = []
            danger_count = 0
            caution_count = 0
            safe_count = 0
            my_lane_count = 0
            other_lane_count = 0

            # 3. ê²€ì¶œëœ ê°ì²´ ì²˜ë¦¬
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        class_id = int(box.cls[0])
                        confidence = float(box.conf[0])
                        x1, y1, x2, y2 = map(int, box.xyxy[0])

                        # ì°¨ëŸ‰ ê°ì²´ë§Œ ì²˜ë¦¬
                        if class_id in VEHICLE_CLASSES:
                            vehicle_name = VEHICLE_CLASSES[class_id]

                            # ê°ì²´ì˜ í•˜ë‹¨ ì¤‘ì•™ì  (ì§€ë©´ ì ‘ì´‰ì )
                            bottom_center = ((x1 + x2) // 2, y2)

                            # ê±°ë¦¬ ê³„ì‚°
                            distance = self.calculate_distance_by_interpolation(
                                [x1, y1, x2, y2], frame.shape[0])

                            # ìì°¨ ì°¨ì„  ë‚´ë¶€ í™•ì¸
                            is_my_lane = self.lane_detector.is_point_in_my_lane(
                                bottom_center, left_lane, right_lane, frame.shape[1])

                            if is_my_lane:
                                my_lane_count += 1

                                # ê±°ë¦¬ì— ë”°ë¥¸ ìƒ‰ìƒê³¼ ìƒíƒœ ê²°ì •
                                color, status = self.get_distance_color_and_status(distance)

                                # ìƒíƒœë³„ ì¹´ìš´íŠ¸ ì¦ê°€
                                if status == "DANGER":
                                    danger_count += 1
                                    # ìœ„í—˜ ê±°ë¦¬ì—ì„œë§Œ ìŒì„± ê²½ê³ 
                                    self.speak_warning(vehicle_name, distance)
                                elif status == "CAUTION":
                                    caution_count += 1
                                else:
                                    safe_count += 1

                                # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                                cv2.rectangle(distance_frame, (x1, y1), (x2, y2), color, 4)

                                # ì§€ë©´ ì ‘ì´‰ì  í‘œì‹œ
                                cv2.circle(distance_frame, bottom_center, 8, color, -1)

                                # ì •ë³´ ë¼ë²¨ í‘œì‹œ
                                label = f"{vehicle_name}: {distance:.1f}m [{status}]"
                                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]

                                # ë¼ë²¨ ë°°ê²½ ê·¸ë¦¬ê¸°
                                cv2.rectangle(distance_frame, (x1, y1 - label_size[1] - 10),
                                              (x1 + label_size[0] + 10, y1), color, -1)

                                # ë¼ë²¨ í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
                                cv2.putText(distance_frame, label, (x1 + 5, y1 - 5),
                                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

                                # ì‹ ë¢°ë„ í‘œì‹œ
                                cv2.putText(distance_frame, f"{confidence:.2f}", (x2 - 40, y1 + 15),
                                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)

                                # ê²€ì¶œ ì •ë³´ ì €ì¥
                                vehicles_with_distance.append({
                                    'name': vehicle_name,
                                    'distance': distance,
                                    'status': status,
                                    'confidence': confidence,
                                    'my_lane': True
                                })

                            else:
                                other_lane_count += 1
                                # íƒ€ì°¨ì„  ì°¨ëŸ‰ì€ íšŒìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ
                                cv2.rectangle(distance_frame, (x1, y1), (x2, y2),
                                              (128, 128, 128), 2, cv2.LINE_4)

                                # íƒ€ì°¨ì„  ë¼ë²¨
                                other_label = f"{vehicle_name}: {distance:.1f}m [other lane]"
                                cv2.putText(distance_frame, other_label, (x1, y1 - 10),
                                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (128, 128, 128), 1)

            # 4. í†µê³„ ì •ë³´ í‘œì‹œ
            stats_text = f"My Lane: {my_lane_count} | Other: {other_lane_count} | " \
                         f"Danger: {danger_count} | Caution: {caution_count} | Safe: {safe_count}"
            cv2.putText(distance_frame, stats_text, (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

            # 5. ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
            # TTS ìƒíƒœ
            tts_status = "TTS: OK" if self.speaker.tts_available else "TTS: FAIL"
            tts_color = (0, 255, 0) if self.speaker.tts_available else (0, 0, 255)
            cv2.putText(distance_frame, tts_status, (10, distance_frame.shape[0] - 90),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, tts_color, 2)

            # ì°¨ì„  ê²€ì¶œ ìƒíƒœ
            if left_lane and right_lane:
                lane_status = "BOTH BOUNDARIES OK"
                lane_color = (0, 255, 0)
            elif left_lane:
                lane_status = "LEFT BOUNDARY ONLY"
                lane_color = (0, 0, 255)
            elif right_lane:
                lane_status = "RIGHT BOUNDARY ONLY"
                lane_color = (255, 0, 0)
            else:
                lane_status = "NO BOUNDARIES"
                lane_color = (128, 128, 128)

            cv2.putText(distance_frame, f"Lane: {lane_status}", (10, 60),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, lane_color, 2)

            # 6. ë²”ë¡€ í‘œì‹œ
            legend_y = distance_frame.shape[0] - 60

            # ì•ˆì „ (ì´ˆë¡ìƒ‰)
            cv2.rectangle(distance_frame, (10, legend_y - 15), (30, legend_y), (0, 255, 0), -1)
            cv2.putText(distance_frame, f"Safe (>{self.caution_distance}m)", (35, legend_y - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)

            # ì£¼ì˜ (ì£¼í™©ìƒ‰)
            cv2.rectangle(distance_frame, (180, legend_y - 15), (200, legend_y), (0, 165, 255), -1)
            cv2.putText(distance_frame, f"Caution ({self.warning_distance}-{self.caution_distance}m)",
                        (205, legend_y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)

            # ìœ„í—˜ (ë¹¨ê°„ìƒ‰)
            cv2.rectangle(distance_frame, (400, legend_y - 15), (420, legend_y), (0, 0, 255), -1)
            cv2.putText(distance_frame, f"Danger (<{self.warning_distance}m)", (425, legend_y - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)

            return distance_frame, vehicles_with_distance

        except Exception as e:
            print(f"âŒ ì°¨ëŸ‰ ê²€ì¶œ ë° ê±°ë¦¬ ì¸¡ì • ì˜¤ë¥˜: {e}")
            return frame, []

    def detect_vehicles(self, frame):
        """
        ë””ë²„ê·¸ìš© ì°¨ëŸ‰ ê²€ì¶œ (ëª¨ë“  ê°ì²´ í‘œì‹œ)
        Args:
            frame: ì…ë ¥ í”„ë ˆì„
        Returns:
            debug_frame: ë””ë²„ê·¸ ì •ë³´ê°€ í‘œì‹œëœ í”„ë ˆì„
            vehicle_count: ê²€ì¶œëœ ì°¨ëŸ‰ ìˆ˜
        """
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_frame = self.preprocessor.preprocess_frame(frame)

            # YOLO ê²€ì¶œ
            results = self.model(
                processed_frame,
                verbose=False,
                conf=self.detection_confidence,
                device='cpu'
            )

            debug_frame = frame.copy()
            detected_count = 0
            vehicle_count = 0

            # ê²€ì¶œëœ ëª¨ë“  ê°ì²´ í‘œì‹œ
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        class_id = int(box.cls[0])
                        confidence = float(box.conf[0])
                        x1, y1, x2, y2 = map(int, box.xyxy[0])

                        # í´ë˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                        class_name = self.model.names[class_id] if class_id in self.model.names else f"class_{class_id}"

                        detected_count += 1

                        # ëª¨ë“  ê°ì²´ë¥¼ í•˜ëŠ˜ìƒ‰ìœ¼ë¡œ í‘œì‹œ
                        cv2.rectangle(debug_frame, (x1, y1), (x2, y2), (255, 255, 0), 2)

                        # ì°¨ëŸ‰ ê°ì²´ì¸ì§€ í™•ì¸
                        if class_id in VEHICLE_CLASSES:
                            vehicle_count += 1

                        # ê°ì²´ ì •ë³´ ë¼ë²¨
                        label = f"{class_name}: {confidence:.2f}"
                        cv2.putText(debug_frame, label, (x1, y1 - 10),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)

            # ê²€ì¶œ í†µê³„ í‘œì‹œ
            stats = f"Total Objects: {detected_count} | Vehicles: {vehicle_count}"
            cv2.putText(debug_frame, stats, (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

            return debug_frame, vehicle_count

        except Exception as e:
            print(f"âŒ ë””ë²„ê·¸ ê²€ì¶œ ì˜¤ë¥˜: {e}")
            return frame, 0

    def run(self, video_path):
        """
        ë©”ì¸ ì‹œìŠ¤í…œ ì‹¤í–‰
        Args:
            video_path: ì…ë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        cap = None
        try:
            print(f"ë¹„ë””ì˜¤ íŒŒì¼ ë¡œë”©: {video_path}")

            # ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸° (ì—¬ëŸ¬ ë°±ì—”ë“œ ì‹œë„)
            cap = cv2.VideoCapture(video_path)

            # ë°±ì—”ë“œ ëŒ€ì²´ ì‹œë„
            if not cap.isOpened():
                cap.release()
                cap = cv2.VideoCapture(video_path, cv2.CAP_FFMPEG)

            if not cap.isOpened():
                cap.release()
                cap = cv2.VideoCapture(video_path, cv2.CAP_ANY)

            if not cap.isOpened():
                print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
                return

            # ë¹„ë””ì˜¤ ì •ë³´ ì¶œë ¥
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            print(f"âœ… ë¹„ë””ì˜¤ ì •ë³´: {width}x{height}, {fps:.1f}fps, {frame_count}í”„ë ˆì„")

            print("=== ì°¨ëŸ‰ ê±°ë¦¬ ì¸¡ì • ë° ê²½ê³  ì‹œìŠ¤í…œ ì‹œì‘ ===")
            print("ì¡°ì‘ë²•: 'q' ì¢…ë£Œ, 'p' ì¼ì‹œì •ì§€/ì¬ìƒ, 'r' ì¬ì‹œì‘, 'h' ì „ì²˜ë¦¬ í† ê¸€")

            frame_count = 0
            paused = False

            # ë©”ì¸ ì²˜ë¦¬ ë£¨í”„
            while True:
                # í”„ë ˆì„ ì½ê¸° (ì¼ì‹œì •ì§€ ìƒíƒœê°€ ì•„ë‹ ë•Œë§Œ)
                if not paused:
                    ret, frame = cap.read()
                    if not ret:
                        print("ğŸ“¹ ë¹„ë””ì˜¤ ì¬ìƒ ì™„ë£Œ")
                        break
                    frame_count += 1

                if 'frame' in locals():
                    # í”„ë ˆì„ í¬ê¸° ì¡°ì •
                    frame = cv2.resize(frame, (IMAGE_WIDTH, IMAGE_HEIGHT))

                    # 1. ë””ë²„ê·¸ ì°½ - YOLO ì›ë³¸ ê²€ì¶œ ê²°ê³¼
                    debug_frame, vehicle_count = self.detect_vehicles(frame)

                    # 2. ë©”ì¸ ì°½ - ê±°ë¦¬ ì¸¡ì • ë° ì•ˆì „ ê²½ê³ 
                    distance_frame, vehicles_with_distance = \
                        self.detect_vehicles_with_distance(frame)

                    # 3. ì „ì²˜ë¦¬ ê²°ê³¼ ì°½ (ì„ íƒì‚¬í•­)
                    if ENABLE_HISTOGRAM_EQUALIZATION:
                        preprocessed_frame = self.preprocessor.preprocess_frame(frame)
                        cv2.imshow('Image Preprocessing Result', preprocessed_frame)

                    # í”„ë ˆì„ ë²ˆí˜¸ í‘œì‹œ
                    frame_info = f"Frame: {frame_count}"
                    cv2.putText(debug_frame, frame_info, (10, debug_frame.shape[0] - 60),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
                    cv2.putText(distance_frame, frame_info, (10, distance_frame.shape[0] - 20),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)

                    # ì¼ì‹œì •ì§€ ìƒíƒœ í‘œì‹œ
                    if paused:
                        cv2.putText(debug_frame, "PAUSED", (IMAGE_WIDTH // 2 - 50, IMAGE_HEIGHT // 2),
                                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)
                        cv2.putText(distance_frame, "PAUSED", (IMAGE_WIDTH // 2 - 50, IMAGE_HEIGHT // 2),
                                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)

                    # ê²°ê³¼ ì°½ í‘œì‹œ
                    cv2.imshow('Debug - YOLO Detection', debug_frame)
                    cv2.imshow('Main - Distance Measurement & Warning', distance_frame)

                # í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(30) & 0xFF

                if key == ord('q'):
                    print("ğŸ”š ì‹œìŠ¤í…œ ì¢…ë£Œ")
                    break
                elif key == ord('p') or key == ord(' '):
                    paused = not paused
                    print(f"{'â¸ï¸ ì¼ì‹œì •ì§€' if paused else 'â–¶ï¸ ì¬ìƒ'}")
                elif key == ord('r'):
                    # ë¹„ë””ì˜¤ ì¬ì‹œì‘
                    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                    frame_count = 0
                    paused = False
                    print("ğŸ”„ ë¹„ë””ì˜¤ ì¬ì‹œì‘")
                elif key == ord('h'):
                    # íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” í† ê¸€
                    self.preprocessor.enable_histogram_eq = not self.preprocessor.enable_histogram_eq
                    status = "ON" if self.preprocessor.enable_histogram_eq else "OFF"
                    print(f"ğŸ¨ íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”: {status}")

        except Exception as e:
            print(f"âŒ ì‹œìŠ¤í…œ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()

        finally:
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            if cap:
                cap.release()
            cv2.destroyAllWindows()
            if hasattr(self, 'speaker'):
                self.speaker.stop()
            print("âœ… ì‹œìŠ¤í…œ ì¢…ë£Œ ì™„ë£Œ")


def main():
    """
    ë©”ì¸ í•¨ìˆ˜ - í”„ë¡œê·¸ë¨ ì§„ì…ì 
    """
    try:
        print("=== ì°¨ëŸ‰ ê±°ë¦¬ ì¸¡ì • ë° ê²½ê³  ì‹œìŠ¤í…œ ===")
        print("ê°œë°œ: AI ê¸°ë°˜ ì‹¤ì‹œê°„ ì•ˆì „ ìš´ì „ ì§€ì› ì‹œìŠ¤í…œ")
        print("ê¸°ëŠ¥: YOLO ê°ì²´ ê²€ì¶œ, ê±°ë¦¬ ê³„ì‚°, ì°¨ì„  ì¸ì‹, ìŒì„± ê²½ê³ ")
        print("=" * 50)

        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        detector = VehicleDistanceDetector()

        # ë¹„ë””ì˜¤ íŒŒì¼ í™•ì¸ ë° ì‹¤í–‰
        if os.path.exists(VIDEO_PATH):
            detector.run(VIDEO_PATH)
        else:
            print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {VIDEO_PATH}")
            print("í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ ë¹„ë””ì˜¤ íŒŒì¼ë“¤:")
            for file in os.listdir("."):
                if file.endswith(('.mp4', '.avi', '.mov', '.mkv')):
                    print(f"  - {file}")

    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•œ í”„ë¡œê·¸ë¨ ì¤‘ë‹¨")
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

"""
=== ì‹œìŠ¤í…œ êµ¬ì¡° ìš”ì•½ ===

1. ImagePreprocessor: ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ (íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”)
2. SafeSpeaker: ë¹„ë™ê¸° TTS ìŒì„± ê²½ê³  ì‹œìŠ¤í…œ
3. LaneDetector: í—ˆí”„ ë³€í™˜ ê¸°ë°˜ ì°¨ì„  ê²€ì¶œ
4. VehicleDistanceDetector: ë©”ì¸ ì‹œìŠ¤í…œ (YOLO + ê±°ë¦¬ ê³„ì‚°)

=== í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ ===

1. ê°ì²´ ê²€ì¶œ: YOLOv8ì„ ì´ìš©í•œ ì‹¤ì‹œê°„ ì°¨ëŸ‰ ê²€ì¶œ
2. ê±°ë¦¬ ê³„ì‚°: ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ê³¼ ì‚¼ê°ë²• ê¸°ë°˜ ê±°ë¦¬ ì¶”ì •
3. ì°¨ì„  ì¸ì‹: Canny ì—£ì§€ + í—ˆí”„ ë³€í™˜ì„ ì´ìš©í•œ ì°¨ì„  ê²½ê³„ ê²€ì¶œ
4. ì•ˆì „ íŒë‹¨: ìì°¨ ì°¨ì„  ë‚´ ê°ì²´ë§Œ í•„í„°ë§í•˜ì—¬ ì•ˆì „ ê±°ë¦¬ ê²½ê³ 

=== ê¸°ìˆ ì  íŠ¹ì§• ===

- ì‹¤ì‹œê°„ ì²˜ë¦¬ ìµœì í™”
- ë‹¤ì¤‘ ìŠ¤ë ˆë“œ TTS ì‹œìŠ¤í…œ
- ì ì‘í˜• ì´ë¯¸ì§€ ì „ì²˜ë¦¬
- ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° ê¸°ë°˜ ì •í™•í•œ ê±°ë¦¬ ì¸¡ì •
- ì§ê´€ì ì¸ ì‹œê°ì  í”¼ë“œë°± (ìƒ‰ìƒ ì½”ë”©)
"""